#!/usr/bin/env python3
import argparse
from html.parser import HTMLParser
from pathlib import Path
import re
import sys
import urllib.request

# Pass the URL to the main yachtworld page for the boat as a
# command line argument.
command_line_parser = argparse.ArgumentParser(
    description='Download high-res images for a boat on yachtworld.',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)
command_line_parser.add_argument('url', help='URL to boat on yachtworld.com')
command_line_parser.add_argument('--output-dir',
    help='directory into which images will be downloaded',
    default='Downloads')
args = command_line_parser.parse_args()
print('Getting images for {}'.format(args.url))

# Yachtworld seems to use a unique ID for each boat. We can parse this
# from the URL.
m = re.search(r'([^/]+?)([0-9]+)/', args.url)
if m is None:
    print('Unable to parse boat id from url', file=sys.stderr)
    sys.exit(1)
boat_name, boat_id = m.groups()
print('Boat ID: {}'.format(boat_id))
output_directory = Path.home() / Path(args.output_dir) / (boat_name + boat_id)
print('Output directory: {}'.format(output_directory))
output_directory.mkdir(parents=True, exist_ok=True)

# Download the page
html_text = urllib.request.urlopen(args.url).read().decode()

# Find and download all images of this boat. There may be pictures of
# other boats on various parts of the page, so we need to check that
# the boat ID is in the image name.
image_urls = set(re.findall(fr'https://[^"?]+?{boat_id}[^"?]+\.jpg', html_text))
image_index = 1
for url in set(image_urls):
    print('Downloading {}'.format(url))
    image_bytes = urllib.request.urlopen(url).read()
    output_path = output_directory / Path('{}.jpg'.format(image_index))
    with output_path.open('wb') as f:
        f.write(image_bytes)

    image_index += 1
